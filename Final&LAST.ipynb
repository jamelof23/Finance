{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamelof23/Finance/blob/main/Final%26LAST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**FMP**\n",
        "\n",
        "*   change program to less than 750 per minList item\n",
        "*   change program to less than 750 per min\n",
        "*   speed is 750 per min , i did 16k in 8 min\n",
        "* changed to 700 per min, Specs is 750\n"
      ],
      "metadata": {
        "id": "rjSiNNO95_Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "import time\n",
        "import openpyxl\n",
        "\n",
        "# Your Financial Modeling Prep API key\n",
        "API_KEY = 'KcsOu8cJesk2GpAJ0DXN4a5Il3DlLUX1'\n",
        "BASE_URL = 'https://financialmodelingprep.com/api/v4/insider-trading'\n",
        "ALL_SYMBOLS_URL = f\"https://financialmodelingprep.com/api/v3/stock/list?apikey={API_KEY}\"\n",
        "\n",
        "RATE_LIMIT = 700  # Requests per minute\n",
        "DELAY_BETWEEN_REQUESTS = 60 / RATE_LIMIT  # Delay in seconds to respect the rate limit\n",
        "\n",
        "def fetch_all_symbols():\n",
        "    \"\"\"Fetch all available U.S. stock symbols from NASDAQ and NYSE.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(ALL_SYMBOLS_URL)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        symbols = [item['symbol'] for item in data if item['exchangeShortName'] in ['NASDAQ', 'NYSE']]\n",
        "        return symbols\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching all symbols: {e}\")\n",
        "        return []\n",
        "\n",
        "def fetch_insider_trading(symbol):\n",
        "    \"\"\"Fetch insider trading data for a given symbol with retry logic.\"\"\"\n",
        "    url = f\"{BASE_URL}?symbol={symbol}&apikey={API_KEY}\"\n",
        "    retries = 3  # Retry up to 3 times\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            if data:\n",
        "                return symbol, data\n",
        "            else:\n",
        "                return symbol, None\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(1)  # Wait 1 second before retrying\n",
        "            else:\n",
        "                print(f\"Failed to fetch data for {symbol} after {retries} attempts.\")\n",
        "                return symbol, None\n",
        "\n",
        "def fetch_all_data(symbols):\n",
        "    \"\"\"Fetch insider trading data for all symbols using parallel processing.\"\"\"\n",
        "    fetched_data = []\n",
        "    total_symbols = len(symbols)\n",
        "    not_fetched_symbols = []\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        futures = {executor.submit(fetch_insider_trading, symbol): symbol for symbol in symbols}\n",
        "        completed = 0\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            symbol, data = future.result()\n",
        "            if data:\n",
        "                for transaction in data:\n",
        "                    transaction['Symbol'] = symbol\n",
        "                    fetched_data.append(transaction)\n",
        "                print(f\"Fetched data for {symbol} successfully.\")\n",
        "            else:\n",
        "                not_fetched_symbols.append(symbol)\n",
        "                print(f\"No data found for {symbol}.\")\n",
        "\n",
        "            completed += 1\n",
        "            print(f\"{completed} out of {total_symbols} symbols completed.\")\n",
        "\n",
        "            # Respect rate limit\n",
        "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
        "\n",
        "    return fetched_data, not_fetched_symbols\n",
        "\n",
        "def save_to_excel(data, filename='Insider_Transactions_FMP.xlsx'):\n",
        "    \"\"\"Save fetched data to an Excel file.\"\"\"\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"\\nData saved to {filename}\")\n",
        "\n",
        "def save_symbols_to_excel(symbols, not_fetched, filename='All_Symbols_FMP.xlsx'):\n",
        "    \"\"\"Save all symbols to an Excel file, with an additional column for data fetched status.\"\"\"\n",
        "    df = pd.DataFrame({'Symbol': symbols, 'Data_Fetched': [symbol not in not_fetched for symbol in symbols]})\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"\\nSymbols saved to {filename}\")\n",
        "\n",
        "# Step 1: Fetch all U.S. stock symbols\n",
        "symbols = fetch_all_symbols()\n",
        "print(f\"Total symbols fetched: {len(symbols)}\")\n",
        "\n",
        "# Step 2: Fetch insider trading data for all symbols and display progress\n",
        "start_time = time.time()\n",
        "fetched_data, not_fetched_symbols = fetch_all_data(symbols)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\nFetched insider trading data for {len(fetched_data)} entries in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "# Step 3: Save the fetched data to an Excel file\n",
        "save_to_excel(fetched_data, 'Insider_Transactions_FMP.xlsx')\n",
        "\n",
        "# Step 4: Save all symbols to a separate Excel file, indicating whether data was fetched or not\n",
        "save_symbols_to_excel(symbols, not_fetched_symbols, 'All_Symbols_FMP.xlsx')\n"
      ],
      "metadata": {
        "id": "O2xHeN0WdjcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Free Code from Fin hub**\n",
        "\n",
        "* today 6 nov , last data was 15 oct available from 1 nov in yahoo\n",
        "* need progress for what is completed how much remaining\n",
        "* need auto download file\n",
        "* G gift for elon why minus should be plus added stovk no value eventhough he filed 3 months later\n",
        "* S sell G gift and minus what is Buy (try put stock has bought if B appears)\n",
        "\n",
        "* need to upload file for all symbols\n",
        "* speed is 55 per min, specs is 60\n",
        "* Free only 50 Symbols\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PjST-yiBaI3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install finnhub-python openpyxl\n",
        "\n",
        "import finnhub\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import files\n",
        "import requests\n",
        "\n",
        "# Replace 'YOUR_API_KEY' with your actual Finnhub API key\n",
        "API_KEY = 'csle2g1r01qq49fgr7lgcsle2g1r01qq49fgr7m0'\n",
        "\n",
        "# Initialize Finnhub client\n",
        "finnhub_client = finnhub.Client(api_key=API_KEY)\n",
        "\n",
        "# Load symbols from your Excel file using read_excel\n",
        "symbols_df = pd.read_excel('/content/All_Symbols_FMP.xlsx')\n",
        "symbol_list = symbols_df['Symbol'].tolist()  # Assuming the column name is 'Symbol'\n",
        "\n",
        "\n",
        "# Function to fetch insider transactions with rate limiting (55 requests per minute)\n",
        "def fetch_insider_transactions(symbols, rate_limit_per_minute=55):\n",
        "    insider_data = []\n",
        "    start_time = time.time()\n",
        "    requests_made = 0\n",
        "    delay_between_requests = 60 / rate_limit_per_minute  # Calculate delay to maintain 55 requests per minute\n",
        "\n",
        "    for idx, symbol in enumerate(symbols):\n",
        "        try:\n",
        "            # Fetch insider transactions with '_from' date\n",
        "            data = finnhub_client.stock_insider_transactions(symbol, _from='2020-01-01')\n",
        "            # Check if data is available\n",
        "            if 'data' in data and data['data']:\n",
        "                for transaction in data['data']:\n",
        "                    insider_data.append(transaction)\n",
        "            else:\n",
        "                print(f\"No insider transactions for symbol {symbol}\")\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            if http_err.response.status_code == 429:\n",
        "                print(\"Rate limit exceeded. Sleeping for a minute.\")\n",
        "                time.sleep(60)\n",
        "            else:\n",
        "                print(f\"HTTP error occurred for symbol {symbol}: {http_err}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data for symbol {symbol}: {e}\")\n",
        "\n",
        "        requests_made += 1\n",
        "\n",
        "        # Implement rate limiting\n",
        "        if requests_made >= rate_limit_per_minute:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            if elapsed_time < 60:\n",
        "                time.sleep(60 - elapsed_time)\n",
        "            start_time = time.time()\n",
        "            requests_made = 0\n",
        "        else:\n",
        "            time.sleep(delay_between_requests)  # Sleep to maintain the rate of 55 requests per minute\n",
        "\n",
        "        # Progress update\n",
        "        if (idx + 1) % 100 == 0:\n",
        "            print(f\"Processed {idx + 1}/{len(symbols)} symbols\")\n",
        "    return insider_data\n",
        "\n",
        "# Initialize insider_transactions\n",
        "insider_transactions = []\n",
        "\n",
        "try:\n",
        "    # Fetch insider transactions\n",
        "    insider_transactions = fetch_insider_transactions(symbol_list)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nProcess interrupted by user. Saving data collected so far...\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Saving data collected so far...\")\n",
        "\n",
        "finally:\n",
        "    if insider_transactions:\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(insider_transactions)\n",
        "\n",
        "        # Save to Excel file\n",
        "        excel_file_name = 'insider_transactions.xlsx'\n",
        "        df.to_excel(excel_file_name, index=False)\n",
        "\n",
        "        # Download the Excel file to your local computer\n",
        "        files.download(excel_file_name)\n",
        "        print(f\"Data saved to {excel_file_name} and downloaded to your local computer.\")\n",
        "    else:\n",
        "        print(\"No data collected to save.\")\n"
      ],
      "metadata": {
        "id": "0aSIvQrgfZ_C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}